{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af992050-eac2-4daa-9ae4-8dd64bd1a072",
   "metadata": {},
   "source": [
    "# Training of the models\n",
    "\n",
    "In this notebook we train **MobileNet, MobileNetV2** and **ResNet50** using both ordinary MSE and MSE that takes into account only the points that are actually visible on the image. At the end we plot the training and validation loss for each model and save trained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9683731f-1433-48ef-812b-9228035cafb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Models.mobilenet_v2 import MobileNetV2Tuned\n",
    "from Models.mobilenet import MobileNetTuned\n",
    "from Models.resnet_50 import ResNetTuned\n",
    "from Data.data_generator import DataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a53810-62fd-4c00-9240-8c2fb4f0fdf2",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Data is loaded through special data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c07e63df-bed4-45c9-a12f-d3e3a2c383a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_generator = DataGenerator(data_path=\"Data/train\", batch_size=batch_size, shuffle=True)\n",
    "val_generator = DataGenerator(data_path=\"Data/val\", batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cccfb39-ef18-41fb-ab06-b9c9e8bba848",
   "metadata": {},
   "source": [
    "## MobileNet\n",
    "\n",
    "### Train with ordinary MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbeb2e2e-8ef7-418c-a348-9b5800aebdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "# Setup the learning rate decay (learning rate is 0.001 for first 10 epochs, then becomes 0.0001 for next 20 epochs and then becomes 0.00001)\n",
    "lr_steps = [5*len(train_generator), 20*len(train_generator)]\n",
    "lr_values = [0.001, 1e-4, 1e-5]\n",
    "lr_scheduler = tf.keras.optimizers.schedules.PiecewiseConstantDecay(lr_steps, lr_values)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "217cca97-10fb-4dd2-88a2-2dee8b1e5102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.cast (TFOpLambda)        (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 224, 224, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 224, 224, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " mobilenet_1.00_224 (Functio  (None, 1024)             3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                18450     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,247,314\n",
      "Trainable params: 3,225,426\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetTuned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd7e85b-523d-4802-8116-032849d9d489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 1962.5736\n",
      "Epoch 1: val_loss improved from inf to 390.98093, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 86s 321ms/step - loss: 1962.5736 - val_loss: 390.9809\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 231.4623\n",
      "Epoch 2: val_loss improved from 390.98093 to 200.63403, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 315ms/step - loss: 231.4623 - val_loss: 200.6340\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 116.8290\n",
      "Epoch 3: val_loss improved from 200.63403 to 133.81087, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 314ms/step - loss: 116.8290 - val_loss: 133.8109\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 69.5462\n",
      "Epoch 4: val_loss improved from 133.81087 to 77.50078, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 317ms/step - loss: 69.5462 - val_loss: 77.5008\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 49.1035\n",
      "Epoch 5: val_loss improved from 77.50078 to 62.37811, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 314ms/step - loss: 49.1035 - val_loss: 62.3781\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 37.1515\n",
      "Epoch 6: val_loss improved from 62.37811 to 47.33791, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 314ms/step - loss: 37.1515 - val_loss: 47.3379\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 34.0231\n",
      "Epoch 7: val_loss improved from 47.33791 to 46.21563, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 81s 322ms/step - loss: 34.0231 - val_loss: 46.2156\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 32.8730\n",
      "Epoch 8: val_loss improved from 46.21563 to 45.55067, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 78s 313ms/step - loss: 32.8730 - val_loss: 45.5507\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 31.1810\n",
      "Epoch 9: val_loss improved from 45.55067 to 45.03086, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 315ms/step - loss: 31.1810 - val_loss: 45.0309\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 29.0301\n",
      "Epoch 10: val_loss improved from 45.03086 to 44.93602, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 80s 319ms/step - loss: 29.0301 - val_loss: 44.9360\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 28.5979\n",
      "Epoch 11: val_loss improved from 44.93602 to 44.89854, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 317ms/step - loss: 28.5979 - val_loss: 44.8985\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 26.8387\n",
      "Epoch 12: val_loss improved from 44.89854 to 44.11005, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 80s 318ms/step - loss: 26.8387 - val_loss: 44.1100\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 25.5735\n",
      "Epoch 13: val_loss did not improve from 44.11005\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 25.5735 - val_loss: 44.1761\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 24.7939\n",
      "Epoch 14: val_loss improved from 44.11005 to 44.08452, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 316ms/step - loss: 24.7939 - val_loss: 44.0845\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 23.2001\n",
      "Epoch 15: val_loss improved from 44.08452 to 43.74341, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 314ms/step - loss: 23.2001 - val_loss: 43.7434\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 22.0011\n",
      "Epoch 16: val_loss improved from 43.74341 to 42.51136, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 80s 318ms/step - loss: 22.0011 - val_loss: 42.5114\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.8647\n",
      "Epoch 17: val_loss improved from 42.51136 to 42.49834, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 317ms/step - loss: 20.8647 - val_loss: 42.4983\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 18.8007\n",
      "Epoch 18: val_loss improved from 42.49834 to 41.22238, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 78s 314ms/step - loss: 18.8007 - val_loss: 41.2224\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 18.1418\n",
      "Epoch 19: val_loss did not improve from 41.22238\n",
      "250/250 [==============================] - 79s 314ms/step - loss: 18.1418 - val_loss: 41.5880\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 16.7254\n",
      "Epoch 20: val_loss improved from 41.22238 to 40.33437, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 16.7254 - val_loss: 40.3344\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 15.2342\n",
      "Epoch 21: val_loss improved from 40.33437 to 39.61509, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 81s 322ms/step - loss: 15.2342 - val_loss: 39.6151\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 15.1270\n",
      "Epoch 22: val_loss improved from 39.61509 to 39.53234, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 316ms/step - loss: 15.1270 - val_loss: 39.5323\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 15.0398\n",
      "Epoch 23: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 81s 325ms/step - loss: 15.0398 - val_loss: 39.6460\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.9928\n",
      "Epoch 24: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 314ms/step - loss: 14.9928 - val_loss: 39.6529\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.7438\n",
      "Epoch 25: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 78s 313ms/step - loss: 14.7438 - val_loss: 39.6017\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.6189\n",
      "Epoch 26: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 78s 310ms/step - loss: 14.6189 - val_loss: 39.6676\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.2415\n",
      "Epoch 27: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 78s 311ms/step - loss: 14.2415 - val_loss: 39.6088\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.3191\n",
      "Epoch 28: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 314ms/step - loss: 14.3191 - val_loss: 39.9381\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.9124\n",
      "Epoch 29: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 315ms/step - loss: 13.9124 - val_loss: 39.9937\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.8586\n",
      "Epoch 30: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 316ms/step - loss: 13.8586 - val_loss: 39.8977\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.6972\n",
      "Epoch 31: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 78s 312ms/step - loss: 13.6972 - val_loss: 40.0760\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.7057\n",
      "Epoch 32: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 81s 326ms/step - loss: 13.7057 - val_loss: 40.2071\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.4631\n",
      "Epoch 33: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 80s 318ms/step - loss: 13.4631 - val_loss: 40.1519\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.3946\n",
      "Epoch 34: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 317ms/step - loss: 13.3946 - val_loss: 40.1157\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.3927\n",
      "Epoch 35: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 78s 312ms/step - loss: 13.3927 - val_loss: 39.8962\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.9975\n",
      "Epoch 36: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 314ms/step - loss: 12.9975 - val_loss: 39.7137\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.9798\n",
      "Epoch 37: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 81s 322ms/step - loss: 12.9798 - val_loss: 39.9692\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.6817\n",
      "Epoch 38: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 78s 311ms/step - loss: 12.6817 - val_loss: 39.8908\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.9116\n",
      "Epoch 39: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 317ms/step - loss: 12.9116 - val_loss: 39.9461\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.6730\n",
      "Epoch 40: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 78s 311ms/step - loss: 12.6730 - val_loss: 40.1056\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.3054\n",
      "Epoch 41: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 316ms/step - loss: 12.3054 - val_loss: 40.1519\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.3443\n",
      "Epoch 42: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 314ms/step - loss: 12.3443 - val_loss: 40.1194\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.2567\n",
      "Epoch 43: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 315ms/step - loss: 12.2567 - val_loss: 40.0352\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.0046\n",
      "Epoch 44: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 317ms/step - loss: 12.0046 - val_loss: 39.9917\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.1592\n",
      "Epoch 45: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 80s 321ms/step - loss: 12.1592 - val_loss: 39.9957\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.8572\n",
      "Epoch 46: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 317ms/step - loss: 11.8572 - val_loss: 39.8504\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.7580\n",
      "Epoch 47: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 314ms/step - loss: 11.7580 - val_loss: 39.9485\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.7640\n",
      "Epoch 48: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 78s 313ms/step - loss: 11.7640 - val_loss: 40.2735\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.7716\n",
      "Epoch 49: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 78s 313ms/step - loss: 11.7716 - val_loss: 40.3139\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.7004\n",
      "Epoch 50: val_loss did not improve from 39.53234\n",
      "250/250 [==============================] - 79s 315ms/step - loss: 11.7004 - val_loss: 39.8045\n"
     ]
    }
   ],
   "source": [
    "train_history = model.train(train_generator, val_generator, epochs=epochs, optimizer=optimizer, loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e587949-ef73-4c8c-b2ed-4f936057dfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at Models/Trained/mobilenet_mse.h5 \n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint that represents the weights with the lower validation loss during the training and save the model\n",
    "model.load_checkpoint()\n",
    "model.save_model(\"mobilenet_mse.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61788e6d-3f1a-4672-837d-8edb7e2990b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(train_history.history['loss'])\n",
    "plt.plot(train_history.history['val_loss'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.savefig('mobilenet_mse.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c01849-2ef8-41ab-88ff-aec0985a4b4a",
   "metadata": {},
   "source": [
    "### Train with convolution instead of pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf4d146-cc79-4162-b5e4-85327ae234a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "# Setup the learning rate decay (learning rate is 0.001 for first 10 epochs, then becomes 0.0001 for next 20 epochs and then becomes 0.00001)\n",
    "lr_steps = [5*len(train_generator), 20*len(train_generator)]\n",
    "lr_values = [0.001, 1e-4, 1e-5]\n",
    "lr_scheduler = tf.keras.optimizers.schedules.PiecewiseConstantDecay(lr_steps, lr_values)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a93f3b3b-b58c-4268-85cd-7224886c5167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.cast (TFOpLambda)        (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 224, 224, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 224, 224, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " mobilenet_1.00_224 (Functio  (None, 7, 7, 1024)       3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 7, 7, 1)           1025      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 49)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                900       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,230,789\n",
      "Trainable params: 3,208,901\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetTuned(pooling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7abfed1-31b2-46d3-a239-9103f2a39c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 720.8063\n",
      "Epoch 1: val_loss improved from inf to 668.65094, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 119s 452ms/step - loss: 720.8063 - val_loss: 668.6509\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 137.3650\n",
      "Epoch 2: val_loss improved from 668.65094 to 193.95782, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 113s 453ms/step - loss: 137.3650 - val_loss: 193.9578\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 72.2769\n",
      "Epoch 3: val_loss improved from 193.95782 to 139.99429, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 100s 402ms/step - loss: 72.2769 - val_loss: 139.9943\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 45.2125\n",
      "Epoch 4: val_loss improved from 139.99429 to 81.58851, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 117s 466ms/step - loss: 45.2125 - val_loss: 81.5885\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 37.5231\n",
      "Epoch 5: val_loss improved from 81.58851 to 79.85901, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 115s 462ms/step - loss: 37.5231 - val_loss: 79.8590\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 25.5813\n",
      "Epoch 6: val_loss improved from 79.85901 to 54.30452, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 109s 438ms/step - loss: 25.5813 - val_loss: 54.3045\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 21.4154\n",
      "Epoch 7: val_loss improved from 54.30452 to 53.03047, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 102s 408ms/step - loss: 21.4154 - val_loss: 53.0305\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 19.4026\n",
      "Epoch 8: val_loss improved from 53.03047 to 52.23302, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 317ms/step - loss: 19.4026 - val_loss: 52.2330\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 17.6640\n",
      "Epoch 9: val_loss improved from 52.23302 to 51.49002, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 79s 316ms/step - loss: 17.6640 - val_loss: 51.4900\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 16.7594\n",
      "Epoch 10: val_loss did not improve from 51.49002\n",
      "250/250 [==============================] - 96s 384ms/step - loss: 16.7594 - val_loss: 51.6263\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 16.1886\n",
      "Epoch 11: val_loss did not improve from 51.49002\n",
      "250/250 [==============================] - 86s 345ms/step - loss: 16.1886 - val_loss: 52.0527\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.8699\n",
      "Epoch 12: val_loss improved from 51.49002 to 50.98499, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 113s 453ms/step - loss: 14.8699 - val_loss: 50.9850\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.1615\n",
      "Epoch 13: val_loss did not improve from 50.98499\n",
      "250/250 [==============================] - 88s 353ms/step - loss: 14.1615 - val_loss: 51.7590\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.2513\n",
      "Epoch 14: val_loss improved from 50.98499 to 50.88008, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 94s 376ms/step - loss: 13.2513 - val_loss: 50.8801\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.6766\n",
      "Epoch 15: val_loss improved from 50.88008 to 50.07901, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 111s 442ms/step - loss: 12.6766 - val_loss: 50.0790\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.0264\n",
      "Epoch 16: val_loss did not improve from 50.07901\n",
      "250/250 [==============================] - 91s 365ms/step - loss: 12.0264 - val_loss: 51.2144\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.3118\n",
      "Epoch 17: val_loss did not improve from 50.07901\n",
      "250/250 [==============================] - 109s 437ms/step - loss: 11.3118 - val_loss: 51.5614\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 10.5760\n",
      "Epoch 18: val_loss did not improve from 50.07901\n",
      "250/250 [==============================] - 96s 382ms/step - loss: 10.5760 - val_loss: 50.7280\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 10.1128\n",
      "Epoch 19: val_loss did not improve from 50.07901\n",
      "250/250 [==============================] - 121s 484ms/step - loss: 10.1128 - val_loss: 51.7890\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 9.5535\n",
      "Epoch 20: val_loss did not improve from 50.07901\n",
      "250/250 [==============================] - 86s 344ms/step - loss: 9.5535 - val_loss: 52.0157\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 8.2872\n",
      "Epoch 21: val_loss improved from 50.07901 to 49.68814, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 87s 347ms/step - loss: 8.2872 - val_loss: 49.6881\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 7.9691\n",
      "Epoch 22: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 127s 509ms/step - loss: 7.9691 - val_loss: 49.7338\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 7.7533\n",
      "Epoch 23: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 116s 462ms/step - loss: 7.7533 - val_loss: 49.7680\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 7.5733\n",
      "Epoch 24: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 116s 463ms/step - loss: 7.5733 - val_loss: 49.9085\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 7.5115\n",
      "Epoch 25: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 95s 382ms/step - loss: 7.5115 - val_loss: 50.0918\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 7.3636\n",
      "Epoch 26: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 91s 365ms/step - loss: 7.3636 - val_loss: 50.4581\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 7.3349\n",
      "Epoch 27: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 112s 449ms/step - loss: 7.3349 - val_loss: 50.2380\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 7.2169\n",
      "Epoch 28: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 116s 462ms/step - loss: 7.2169 - val_loss: 50.2790\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.9884\n",
      "Epoch 29: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 120s 479ms/step - loss: 6.9884 - val_loss: 50.0791\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 7.0021\n",
      "Epoch 30: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 124s 494ms/step - loss: 7.0021 - val_loss: 50.2901\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.9687\n",
      "Epoch 31: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 97s 386ms/step - loss: 6.9687 - val_loss: 50.6051\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.8201\n",
      "Epoch 32: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 80s 318ms/step - loss: 6.8201 - val_loss: 50.5863\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.7486\n",
      "Epoch 33: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 80s 319ms/step - loss: 6.7486 - val_loss: 50.5301\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.6944\n",
      "Epoch 34: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 79s 315ms/step - loss: 6.6944 - val_loss: 50.6773\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.4663\n",
      "Epoch 35: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 118s 471ms/step - loss: 6.4663 - val_loss: 50.8475\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.4870\n",
      "Epoch 36: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 116s 464ms/step - loss: 6.4870 - val_loss: 50.6125\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.4556\n",
      "Epoch 37: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 96s 382ms/step - loss: 6.4556 - val_loss: 50.7090\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.3615\n",
      "Epoch 38: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 98s 393ms/step - loss: 6.3615 - val_loss: 50.7500\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.3029\n",
      "Epoch 39: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 6.3029 - val_loss: 51.0073\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.2212\n",
      "Epoch 40: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 78s 313ms/step - loss: 6.2212 - val_loss: 50.7814\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.1235\n",
      "Epoch 41: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 6.1235 - val_loss: 51.4489\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.0140\n",
      "Epoch 42: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 83s 331ms/step - loss: 6.0140 - val_loss: 50.7902\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 6.0112\n",
      "Epoch 43: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 87s 347ms/step - loss: 6.0112 - val_loss: 51.1145\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 5.9223\n",
      "Epoch 44: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 5.9223 - val_loss: 50.9074\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 5.9398\n",
      "Epoch 45: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 5.9398 - val_loss: 51.1339\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 5.7964\n",
      "Epoch 46: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 87s 347ms/step - loss: 5.7964 - val_loss: 50.9061\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 5.6821\n",
      "Epoch 47: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 98s 391ms/step - loss: 5.6821 - val_loss: 51.3187\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 5.6528\n",
      "Epoch 48: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 115s 460ms/step - loss: 5.6528 - val_loss: 51.1121\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 5.5608\n",
      "Epoch 49: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 113s 452ms/step - loss: 5.5608 - val_loss: 51.3119\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 5.5424\n",
      "Epoch 50: val_loss did not improve from 49.68814\n",
      "250/250 [==============================] - 108s 433ms/step - loss: 5.5424 - val_loss: 51.0818\n"
     ]
    }
   ],
   "source": [
    "train_history = model.train(train_generator, val_generator, epochs=epochs, optimizer=optimizer, loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "898b883d-0f97-4eae-9109-10f8bc96e75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at Models/Trained/mobilenet_conv.h5 \n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint that represents the weights with the lower validation loss during the training and save the model\n",
    "model.load_checkpoint()\n",
    "model.save_model(\"mobilenet_conv.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e60f44cc-ff02-44c7-a087-1c1f378dfdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(train_history.history['loss'])\n",
    "plt.plot(train_history.history['val_loss'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.savefig('mobilenet_conv.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f060ce1-7f88-49fa-b892-2769166f5468",
   "metadata": {},
   "source": [
    "### Train with modified MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517eefaf-bfff-4b19-ac65-cf9a72e2143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "# Setup the learning rate decay (learning rate is 0.001 for first 10 epochs, then becomes 0.0001 for next 20 epochs and then becomes 0.00001)\n",
    "lr_steps = [5*len(train_generator), 20*len(train_generator)]\n",
    "lr_values = [0.001, 1e-4, 1e-5]\n",
    "lr_scheduler = tf.keras.optimizers.schedules.PiecewiseConstantDecay(lr_steps, lr_values)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f871fd2-7985-416f-9a8a-bf6da0964425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.cast (TFOpLambda)        (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 224, 224, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 224, 224, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " mobilenet_1.00_224 (Functio  (None, 1024)             3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                18450     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,247,314\n",
      "Trainable params: 3,225,426\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetTuned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a73c42ad-4d06-4dc2-bde5-b63eba399d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 1842.1045\n",
      "Epoch 1: val_loss improved from inf to 425.77466, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 89s 332ms/step - loss: 1842.1045 - val_loss: 425.7747\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 220.0544\n",
      "Epoch 2: val_loss improved from 425.77466 to 178.60577, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 84s 336ms/step - loss: 220.0544 - val_loss: 178.6058\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 108.1631\n",
      "Epoch 3: val_loss improved from 178.60577 to 89.02098, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 83s 332ms/step - loss: 108.1631 - val_loss: 89.0210\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 65.7556\n",
      "Epoch 4: val_loss improved from 89.02098 to 74.36864, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 84s 336ms/step - loss: 65.7556 - val_loss: 74.3686\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 54.2065\n",
      "Epoch 5: val_loss did not improve from 74.36864\n",
      "250/250 [==============================] - 80s 319ms/step - loss: 54.2065 - val_loss: 85.4060\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 40.2208\n",
      "Epoch 6: val_loss improved from 74.36864 to 49.09204, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 83s 333ms/step - loss: 40.2208 - val_loss: 49.0920\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 35.0683\n",
      "Epoch 7: val_loss improved from 49.09204 to 47.60704, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 328ms/step - loss: 35.0683 - val_loss: 47.6070\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 33.2799\n",
      "Epoch 8: val_loss improved from 47.60704 to 45.67270, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 83s 333ms/step - loss: 33.2799 - val_loss: 45.6727\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 31.0944\n",
      "Epoch 9: val_loss improved from 45.67270 to 44.72474, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 326ms/step - loss: 31.0944 - val_loss: 44.7247\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 30.7361\n",
      "Epoch 10: val_loss improved from 44.72474 to 43.96807, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 329ms/step - loss: 30.7361 - val_loss: 43.9681\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 28.6065\n",
      "Epoch 11: val_loss improved from 43.96807 to 42.63060, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 328ms/step - loss: 28.6065 - val_loss: 42.6306\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 27.2511\n",
      "Epoch 12: val_loss improved from 42.63060 to 42.46930, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 329ms/step - loss: 27.2511 - val_loss: 42.4693\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 25.3613\n",
      "Epoch 13: val_loss improved from 42.46930 to 41.35827, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 84s 335ms/step - loss: 25.3613 - val_loss: 41.3583\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 24.1769\n",
      "Epoch 14: val_loss improved from 41.35827 to 40.38432, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 88s 351ms/step - loss: 24.1769 - val_loss: 40.3843\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 23.0780\n",
      "Epoch 15: val_loss improved from 40.38432 to 40.00587, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 328ms/step - loss: 23.0780 - val_loss: 40.0059\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 21.5035\n",
      "Epoch 16: val_loss did not improve from 40.00587\n",
      "250/250 [==============================] - 84s 337ms/step - loss: 21.5035 - val_loss: 40.5903\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.5552\n",
      "Epoch 17: val_loss improved from 40.00587 to 39.49507, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 83s 333ms/step - loss: 20.5552 - val_loss: 39.4951\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 19.3196\n",
      "Epoch 18: val_loss improved from 39.49507 to 38.78978, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 85s 340ms/step - loss: 19.3196 - val_loss: 38.7898\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 18.2216\n",
      "Epoch 19: val_loss improved from 38.78978 to 37.91219, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 83s 331ms/step - loss: 18.2216 - val_loss: 37.9122\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 16.9221\n",
      "Epoch 20: val_loss improved from 37.91219 to 36.84486, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 84s 334ms/step - loss: 16.9221 - val_loss: 36.8449\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 16.2356\n",
      "Epoch 21: val_loss improved from 36.84486 to 35.82405, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 329ms/step - loss: 16.2356 - val_loss: 35.8241\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 15.0071\n",
      "Epoch 22: val_loss did not improve from 35.82405\n",
      "250/250 [==============================] - 81s 324ms/step - loss: 15.0071 - val_loss: 35.8692\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 15.1992\n",
      "Epoch 23: val_loss did not improve from 35.82405\n",
      "250/250 [==============================] - 81s 324ms/step - loss: 15.1992 - val_loss: 35.8318\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.9740\n",
      "Epoch 24: val_loss did not improve from 35.82405\n",
      "250/250 [==============================] - 81s 325ms/step - loss: 14.9740 - val_loss: 36.0369\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.8696\n",
      "Epoch 25: val_loss improved from 35.82405 to 35.72843, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 329ms/step - loss: 14.8696 - val_loss: 35.7284\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.3746\n",
      "Epoch 26: val_loss did not improve from 35.72843\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 14.3746 - val_loss: 35.8719\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.3387\n",
      "Epoch 27: val_loss did not improve from 35.72843\n",
      "250/250 [==============================] - 81s 323ms/step - loss: 14.3387 - val_loss: 35.8102\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.3564\n",
      "Epoch 28: val_loss did not improve from 35.72843\n",
      "250/250 [==============================] - 81s 324ms/step - loss: 14.3564 - val_loss: 35.8459\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.1669\n",
      "Epoch 29: val_loss improved from 35.72843 to 35.69522, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 81s 324ms/step - loss: 14.1669 - val_loss: 35.6952\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 14.1759\n",
      "Epoch 30: val_loss did not improve from 35.69522\n",
      "250/250 [==============================] - 84s 335ms/step - loss: 14.1759 - val_loss: 35.8842\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.8595\n",
      "Epoch 31: val_loss did not improve from 35.69522\n",
      "250/250 [==============================] - 81s 324ms/step - loss: 13.8595 - val_loss: 35.7847\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.8282\n",
      "Epoch 32: val_loss did not improve from 35.69522\n",
      "250/250 [==============================] - 81s 322ms/step - loss: 13.8282 - val_loss: 35.7643\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.6964\n",
      "Epoch 33: val_loss improved from 35.69522 to 35.61332, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 328ms/step - loss: 13.6964 - val_loss: 35.6133\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.5802\n",
      "Epoch 34: val_loss improved from 35.61332 to 35.54877, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 329ms/step - loss: 13.5802 - val_loss: 35.5488\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.4827\n",
      "Epoch 35: val_loss did not improve from 35.54877\n",
      "250/250 [==============================] - 80s 321ms/step - loss: 13.4827 - val_loss: 35.5755\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.2436\n",
      "Epoch 36: val_loss did not improve from 35.54877\n",
      "250/250 [==============================] - 80s 321ms/step - loss: 13.2436 - val_loss: 35.5541\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.1995\n",
      "Epoch 37: val_loss improved from 35.54877 to 35.35037, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 328ms/step - loss: 13.1995 - val_loss: 35.3504\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.1355\n",
      "Epoch 38: val_loss did not improve from 35.35037\n",
      "250/250 [==============================] - 81s 322ms/step - loss: 13.1355 - val_loss: 35.4911\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.0894\n",
      "Epoch 39: val_loss improved from 35.35037 to 35.27554, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 326ms/step - loss: 13.0894 - val_loss: 35.2755\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.8218\n",
      "Epoch 40: val_loss did not improve from 35.27554\n",
      "250/250 [==============================] - 81s 326ms/step - loss: 12.8218 - val_loss: 35.4478\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.7877\n",
      "Epoch 41: val_loss did not improve from 35.27554\n",
      "250/250 [==============================] - 80s 321ms/step - loss: 12.7877 - val_loss: 35.3966\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.7679\n",
      "Epoch 42: val_loss improved from 35.27554 to 35.19703, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 82s 326ms/step - loss: 12.7679 - val_loss: 35.1970\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.5271\n",
      "Epoch 43: val_loss improved from 35.19703 to 35.11289, saving model to Models/Checkpoints\\mobilenet.hdf5\n",
      "250/250 [==============================] - 81s 324ms/step - loss: 12.5271 - val_loss: 35.1129\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.3495\n",
      "Epoch 44: val_loss did not improve from 35.11289\n",
      "250/250 [==============================] - 81s 322ms/step - loss: 12.3495 - val_loss: 35.3049\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.2369\n",
      "Epoch 45: val_loss did not improve from 35.11289\n",
      "250/250 [==============================] - 80s 321ms/step - loss: 12.2369 - val_loss: 35.3294\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.2896\n",
      "Epoch 46: val_loss did not improve from 35.11289\n",
      "250/250 [==============================] - 83s 331ms/step - loss: 12.2896 - val_loss: 35.4445\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.0095\n",
      "Epoch 47: val_loss did not improve from 35.11289\n",
      "250/250 [==============================] - 81s 324ms/step - loss: 12.0095 - val_loss: 35.4290\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.9636\n",
      "Epoch 48: val_loss did not improve from 35.11289\n",
      "250/250 [==============================] - 81s 326ms/step - loss: 11.9636 - val_loss: 35.2237\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.9762\n",
      "Epoch 49: val_loss did not improve from 35.11289\n",
      "250/250 [==============================] - 81s 323ms/step - loss: 11.9762 - val_loss: 35.2627\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.5923\n",
      "Epoch 50: val_loss did not improve from 35.11289\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 11.5923 - val_loss: 35.3118\n"
     ]
    }
   ],
   "source": [
    "train_history = model.train(train_generator, val_generator, epochs=epochs, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21fa0a30-74f5-4238-87b5-78d965707eee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function: mse_visible. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the checkpoint that represents the weights with the lower validation loss during the training and save the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\faks\\Deep learning\\Project\\dl_project\\Models\\parent_model.py:55\u001b[0m, in \u001b[0;36mParentModel.load_checkpoint\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_checkpoint\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     54\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(CHECKPOINT_DIR, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl_project\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl_project\\lib\\site-packages\\keras\\utils\\generic_utils.py:709\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    707\u001b[0m   obj \u001b[38;5;241m=\u001b[39m module_objects\u001b[38;5;241m.\u001b[39mget(object_name)\n\u001b[0;32m    708\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 709\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprintable_module_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please ensure \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    711\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis object is passed to the `custom_objects` argument. See \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    712\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    713\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#registering_the_custom_object for details.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# returned as-is.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_inspect\u001b[38;5;241m.\u001b[39misclass(obj):\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown loss function: mse_visible. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "# Load the checkpoint that represents the weights with the lower validation loss during the training and save the model\n",
    "model.load_checkpoint()\n",
    "#model.save_model(\"mobilenet_custom.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ab3c0-24aa-444a-b5f5-e361c841c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(train_history.history['loss'])\n",
    "plt.plot(train_history.history['val_loss'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.savefig('mobilenet_custom.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35793da0-c220-422e-9705-c85da46e2ab9",
   "metadata": {},
   "source": [
    "## MobileNetV2\n",
    "\n",
    "### Train with ordinary MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f15cc3af-b654-4891-a071-cf5b06ba5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "# Setup the learning rate decay (learning rate is 0.001 for first 10 epochs, then becomes 0.0001 for next 20 epochs and then becomes 0.00001)\n",
    "lr_steps = [10*len(train_generator), 30*len(train_generator)]\n",
    "lr_values = [0.001, 1e-4, 1e-5]\n",
    "lr_scheduler = tf.keras.optimizers.schedules.PiecewiseConstantDecay(lr_steps, lr_values)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b4d73b9-dce7-4dec-ad5a-eeb2445bb0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.cast (TFOpLambda)        (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 224, 224, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 224, 224, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                23058     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,281,042\n",
      "Trainable params: 2,246,930\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2Tuned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f6eac6f-2cd0-4448-a7a4-c8443a3baae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 2618.8438\n",
      "Epoch 1: val_loss improved from inf to 3401.76416, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 119s 440ms/step - loss: 2618.8438 - val_loss: 3401.7642\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 521.4677\n",
      "Epoch 2: val_loss improved from 3401.76416 to 1543.04456, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 107s 427ms/step - loss: 521.4677 - val_loss: 1543.0446\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 226.8395\n",
      "Epoch 3: val_loss improved from 1543.04456 to 347.09503, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 108s 433ms/step - loss: 226.8395 - val_loss: 347.0950\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 175.7278\n",
      "Epoch 4: val_loss did not improve from 347.09503\n",
      "250/250 [==============================] - 109s 436ms/step - loss: 175.7278 - val_loss: 521.4833\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 108.9761\n",
      "Epoch 5: val_loss did not improve from 347.09503\n",
      "250/250 [==============================] - 109s 438ms/step - loss: 108.9761 - val_loss: 619.6711\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 66.8053\n",
      "Epoch 6: val_loss improved from 347.09503 to 278.16376, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 105s 420ms/step - loss: 66.8053 - val_loss: 278.1638\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 51.8359\n",
      "Epoch 7: val_loss improved from 278.16376 to 159.74651, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 110s 441ms/step - loss: 51.8359 - val_loss: 159.7465\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 46.2964\n",
      "Epoch 8: val_loss did not improve from 159.74651\n",
      "250/250 [==============================] - 108s 431ms/step - loss: 46.2964 - val_loss: 182.4175\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 41.6798\n",
      "Epoch 9: val_loss did not improve from 159.74651\n",
      "250/250 [==============================] - 108s 432ms/step - loss: 41.6798 - val_loss: 223.6119\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 37.2190\n",
      "Epoch 10: val_loss did not improve from 159.74651\n",
      "250/250 [==============================] - 107s 430ms/step - loss: 37.2190 - val_loss: 181.0294\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 29.8859\n",
      "Epoch 11: val_loss improved from 159.74651 to 125.04134, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 109s 436ms/step - loss: 29.8859 - val_loss: 125.0413\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 28.1830\n",
      "Epoch 12: val_loss improved from 125.04134 to 80.22314, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 115s 459ms/step - loss: 28.1830 - val_loss: 80.2231\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 26.7829\n",
      "Epoch 13: val_loss improved from 80.22314 to 60.50529, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 107s 429ms/step - loss: 26.7829 - val_loss: 60.5053\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 25.8372\n",
      "Epoch 14: val_loss improved from 60.50529 to 54.49832, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 107s 427ms/step - loss: 25.8372 - val_loss: 54.4983\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 25.1471\n",
      "Epoch 15: val_loss improved from 54.49832 to 50.78028, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 109s 436ms/step - loss: 25.1471 - val_loss: 50.7803\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 23.7332\n",
      "Epoch 16: val_loss improved from 50.78028 to 50.15601, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 110s 439ms/step - loss: 23.7332 - val_loss: 50.1560\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 23.5074\n",
      "Epoch 17: val_loss improved from 50.15601 to 49.08518, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 111s 442ms/step - loss: 23.5074 - val_loss: 49.0852\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 22.9094\n",
      "Epoch 18: val_loss did not improve from 49.08518\n",
      "250/250 [==============================] - 106s 424ms/step - loss: 22.9094 - val_loss: 49.9616\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 21.5980\n",
      "Epoch 19: val_loss did not improve from 49.08518\n",
      "250/250 [==============================] - 108s 432ms/step - loss: 21.5980 - val_loss: 51.0827\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.9308\n",
      "Epoch 20: val_loss did not improve from 49.08518\n",
      "250/250 [==============================] - 108s 433ms/step - loss: 20.9308 - val_loss: 53.8894\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.2109\n",
      "Epoch 21: val_loss did not improve from 49.08518\n",
      "250/250 [==============================] - 105s 421ms/step - loss: 20.2109 - val_loss: 51.2224\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.2178\n",
      "Epoch 22: val_loss did not improve from 49.08518\n",
      "250/250 [==============================] - 107s 429ms/step - loss: 20.2178 - val_loss: 49.2371\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 19.2044\n",
      "Epoch 23: val_loss improved from 49.08518 to 47.94429, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 105s 419ms/step - loss: 19.2044 - val_loss: 47.9443\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 18.2635\n",
      "Epoch 24: val_loss did not improve from 47.94429\n",
      "250/250 [==============================] - 110s 440ms/step - loss: 18.2635 - val_loss: 49.1535\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 17.9450\n",
      "Epoch 25: val_loss did not improve from 47.94429\n",
      "250/250 [==============================] - 108s 431ms/step - loss: 17.9450 - val_loss: 49.5628\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 17.7325\n",
      "Epoch 26: val_loss did not improve from 47.94429\n",
      "250/250 [==============================] - 108s 432ms/step - loss: 17.7325 - val_loss: 50.3055\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 16.9420\n",
      "Epoch 27: val_loss did not improve from 47.94429\n",
      "250/250 [==============================] - 105s 422ms/step - loss: 16.9420 - val_loss: 57.2865\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 16.3375\n",
      "Epoch 28: val_loss did not improve from 47.94429\n",
      "250/250 [==============================] - 110s 440ms/step - loss: 16.3375 - val_loss: 51.5364\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 15.2824\n",
      "Epoch 29: val_loss did not improve from 47.94429\n",
      "250/250 [==============================] - 107s 427ms/step - loss: 15.2824 - val_loss: 58.2622\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 15.1437\n",
      "Epoch 30: val_loss did not improve from 47.94429\n",
      "250/250 [==============================] - 110s 438ms/step - loss: 15.1437 - val_loss: 52.2345\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.2389\n",
      "Epoch 31: val_loss improved from 47.94429 to 45.88316, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 109s 435ms/step - loss: 13.2389 - val_loss: 45.8832\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 13.0312\n",
      "Epoch 32: val_loss improved from 45.88316 to 44.26033, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 107s 429ms/step - loss: 13.0312 - val_loss: 44.2603\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.8141\n",
      "Epoch 33: val_loss improved from 44.26033 to 43.08137, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 107s 427ms/step - loss: 12.8141 - val_loss: 43.0814\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.7771\n",
      "Epoch 34: val_loss improved from 43.08137 to 42.23730, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 108s 433ms/step - loss: 12.7771 - val_loss: 42.2373\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.5322\n",
      "Epoch 35: val_loss improved from 42.23730 to 41.70851, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 110s 439ms/step - loss: 12.5322 - val_loss: 41.7085\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.6373\n",
      "Epoch 36: val_loss improved from 41.70851 to 41.49014, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 108s 432ms/step - loss: 12.6373 - val_loss: 41.4901\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.5415\n",
      "Epoch 37: val_loss improved from 41.49014 to 40.73151, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 110s 441ms/step - loss: 12.5415 - val_loss: 40.7315\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.2880\n",
      "Epoch 38: val_loss improved from 40.73151 to 40.18492, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 104s 415ms/step - loss: 12.2880 - val_loss: 40.1849\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.2128\n",
      "Epoch 39: val_loss did not improve from 40.18492\n",
      "250/250 [==============================] - 105s 422ms/step - loss: 12.2128 - val_loss: 40.2230\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.2363\n",
      "Epoch 40: val_loss did not improve from 40.18492\n",
      "250/250 [==============================] - 105s 421ms/step - loss: 12.2363 - val_loss: 40.6153\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.0937\n",
      "Epoch 41: val_loss did not improve from 40.18492\n",
      "250/250 [==============================] - 104s 418ms/step - loss: 12.0937 - val_loss: 40.7862\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.9690\n",
      "Epoch 42: val_loss did not improve from 40.18492\n",
      "250/250 [==============================] - 106s 426ms/step - loss: 11.9690 - val_loss: 40.2005\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.8689\n",
      "Epoch 43: val_loss improved from 40.18492 to 40.11128, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 111s 443ms/step - loss: 11.8689 - val_loss: 40.1113\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.8716\n",
      "Epoch 44: val_loss improved from 40.11128 to 40.08155, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 111s 443ms/step - loss: 11.8716 - val_loss: 40.0815\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.8257\n",
      "Epoch 45: val_loss did not improve from 40.08155\n",
      "250/250 [==============================] - 110s 438ms/step - loss: 11.8257 - val_loss: 40.1629\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.6553\n",
      "Epoch 46: val_loss did not improve from 40.08155\n",
      "250/250 [==============================] - 107s 428ms/step - loss: 11.6553 - val_loss: 40.1576\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.6200\n",
      "Epoch 47: val_loss did not improve from 40.08155\n",
      "250/250 [==============================] - 108s 434ms/step - loss: 11.6200 - val_loss: 40.6432\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.5999\n",
      "Epoch 48: val_loss did not improve from 40.08155\n",
      "250/250 [==============================] - 109s 437ms/step - loss: 11.5999 - val_loss: 40.2502\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.5740\n",
      "Epoch 49: val_loss did not improve from 40.08155\n",
      "250/250 [==============================] - 110s 441ms/step - loss: 11.5740 - val_loss: 40.2530\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 11.4854\n",
      "Epoch 50: val_loss did not improve from 40.08155\n",
      "250/250 [==============================] - 108s 431ms/step - loss: 11.4854 - val_loss: 40.4853\n"
     ]
    }
   ],
   "source": [
    "train_history = model.train(train_generator, val_generator, epochs=epochs, optimizer=optimizer, loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23cdba96-cbb5-425a-8b9a-bec61c72ee21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at Models/Trained/mobilenet_v2_mse.h5 \n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint that represents the weights with the lower validation loss during the training and save the model\n",
    "model.load_checkpoint()\n",
    "model.save_model(\"mobilenet_v2_mse.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a445d4ab-7b85-41b2-b2f1-aa05edf9141e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(train_history.history['loss'])\n",
    "plt.plot(train_history.history['val_loss'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.savefig('mobilenet_v2_mse.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdba646-eeb5-4791-b5fb-4049c75bdea0",
   "metadata": {},
   "source": [
    "### Train with modified MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f179b1a0-c356-4b61-bb0b-0fb8549e34c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "# Setup the learning rate decay (learning rate is 0.001 for first 10 epochs, then becomes 0.0001 for next 20 epochs and then becomes 0.00001)\n",
    "lr_steps = [5*len(train_generator), 20*len(train_generator)]\n",
    "lr_values = [0.001, 1e-4, 1e-5]\n",
    "lr_scheduler = tf.keras.optimizers.schedules.PiecewiseConstantDecay(lr_steps, lr_values)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f64524e-521c-479a-a629-e85b0ca9db79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.cast (TFOpLambda)        (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 224, 224, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 224, 224, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                23058     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,281,042\n",
      "Trainable params: 2,246,930\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2Tuned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d144154a-3a58-4cc4-91f7-06c5e5f9ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 2376.7219\n",
      "Epoch 1: val_loss improved from inf to 7009.29443, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 218s 805ms/step - loss: 2376.7219 - val_loss: 7009.2944\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 436.3803\n",
      "Epoch 2: val_loss improved from 7009.29443 to 614.29340, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 123s 492ms/step - loss: 436.3803 - val_loss: 614.2934\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 202.6281\n",
      "Epoch 3: val_loss improved from 614.29340 to 401.21704, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 120s 481ms/step - loss: 202.6281 - val_loss: 401.2170\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 134.0261\n",
      "Epoch 4: val_loss improved from 401.21704 to 255.53561, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 124s 494ms/step - loss: 134.0261 - val_loss: 255.5356\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 93.0468\n",
      "Epoch 5: val_loss did not improve from 255.53561\n",
      "250/250 [==============================] - 120s 481ms/step - loss: 93.0468 - val_loss: 327.5249\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 60.1081\n",
      "Epoch 6: val_loss improved from 255.53561 to 170.06364, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 123s 493ms/step - loss: 60.1081 - val_loss: 170.0636\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 52.7462\n",
      "Epoch 7: val_loss improved from 170.06364 to 136.44743, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 119s 476ms/step - loss: 52.7462 - val_loss: 136.4474\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 49.0293\n",
      "Epoch 8: val_loss improved from 136.44743 to 114.78762, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 119s 477ms/step - loss: 49.0293 - val_loss: 114.7876\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 46.5754\n",
      "Epoch 9: val_loss did not improve from 114.78762\n",
      "250/250 [==============================] - 125s 499ms/step - loss: 46.5754 - val_loss: 122.5918\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 42.4307\n",
      "Epoch 10: val_loss improved from 114.78762 to 95.79926, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 120s 479ms/step - loss: 42.4307 - val_loss: 95.7993\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 39.3854\n",
      "Epoch 11: val_loss did not improve from 95.79926\n",
      "250/250 [==============================] - 122s 485ms/step - loss: 39.3854 - val_loss: 106.1090\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 38.3321\n",
      "Epoch 12: val_loss improved from 95.79926 to 84.65461, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 121s 485ms/step - loss: 38.3321 - val_loss: 84.6546\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 36.3897\n",
      "Epoch 13: val_loss improved from 84.65461 to 82.03628, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 123s 491ms/step - loss: 36.3897 - val_loss: 82.0363\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 34.5741\n",
      "Epoch 14: val_loss improved from 82.03628 to 74.76900, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 34.5741 - val_loss: 74.7690\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 32.6392\n",
      "Epoch 15: val_loss did not improve from 74.76900\n",
      "250/250 [==============================] - 122s 489ms/step - loss: 32.6392 - val_loss: 76.9635\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 31.6785\n",
      "Epoch 16: val_loss improved from 74.76900 to 72.78372, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 108s 432ms/step - loss: 31.6785 - val_loss: 72.7837\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 29.9867\n",
      "Epoch 17: val_loss improved from 72.78372 to 65.20783, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 121s 485ms/step - loss: 29.9867 - val_loss: 65.2078\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 28.9937\n",
      "Epoch 18: val_loss improved from 65.20783 to 59.88321, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 121s 486ms/step - loss: 28.9937 - val_loss: 59.8832\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 28.4694\n",
      "Epoch 19: val_loss improved from 59.88321 to 58.06893, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 113s 453ms/step - loss: 28.4694 - val_loss: 58.0689\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 27.0661\n",
      "Epoch 20: val_loss did not improve from 58.06893\n",
      "250/250 [==============================] - 118s 473ms/step - loss: 27.0661 - val_loss: 59.0576\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 24.9914\n",
      "Epoch 21: val_loss improved from 58.06893 to 50.94812, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 121s 484ms/step - loss: 24.9914 - val_loss: 50.9481\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 24.2765\n",
      "Epoch 22: val_loss improved from 50.94812 to 48.62244, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 122s 488ms/step - loss: 24.2765 - val_loss: 48.6224\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 24.4418\n",
      "Epoch 23: val_loss improved from 48.62244 to 45.70032, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 121s 482ms/step - loss: 24.4418 - val_loss: 45.7003\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 23.6979\n",
      "Epoch 24: val_loss improved from 45.70032 to 45.05891, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 23.6979 - val_loss: 45.0589\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 23.3776\n",
      "Epoch 25: val_loss improved from 45.05891 to 43.28905, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 123s 492ms/step - loss: 23.3776 - val_loss: 43.2891\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 23.5187\n",
      "Epoch 26: val_loss did not improve from 43.28905\n",
      "250/250 [==============================] - 117s 469ms/step - loss: 23.5187 - val_loss: 44.3140\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 23.3255\n",
      "Epoch 27: val_loss improved from 43.28905 to 42.74910, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 121s 482ms/step - loss: 23.3255 - val_loss: 42.7491\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 22.5790\n",
      "Epoch 28: val_loss improved from 42.74910 to 42.48826, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 125s 499ms/step - loss: 22.5790 - val_loss: 42.4883\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 22.6855\n",
      "Epoch 29: val_loss improved from 42.48826 to 42.01426, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 124s 496ms/step - loss: 22.6855 - val_loss: 42.0143\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 22.4275\n",
      "Epoch 30: val_loss did not improve from 42.01426\n",
      "250/250 [==============================] - 120s 481ms/step - loss: 22.4275 - val_loss: 42.1949\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 22.8459\n",
      "Epoch 31: val_loss did not improve from 42.01426\n",
      "250/250 [==============================] - 121s 482ms/step - loss: 22.8459 - val_loss: 42.8200\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 22.2062\n",
      "Epoch 32: val_loss did not improve from 42.01426\n",
      "250/250 [==============================] - 121s 486ms/step - loss: 22.2062 - val_loss: 42.1262\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 22.1215\n",
      "Epoch 33: val_loss did not improve from 42.01426\n",
      "250/250 [==============================] - 111s 444ms/step - loss: 22.1215 - val_loss: 42.5968\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 22.2974\n",
      "Epoch 34: val_loss improved from 42.01426 to 41.62103, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 119s 476ms/step - loss: 22.2974 - val_loss: 41.6210\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 22.1034\n",
      "Epoch 35: val_loss improved from 41.62103 to 41.45439, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 123s 492ms/step - loss: 22.1034 - val_loss: 41.4544\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 21.6837\n",
      "Epoch 36: val_loss did not improve from 41.45439\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 21.6837 - val_loss: 41.8010\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 21.7205\n",
      "Epoch 37: val_loss did not improve from 41.45439\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 21.7205 - val_loss: 41.7672\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 21.4111\n",
      "Epoch 38: val_loss did not improve from 41.45439\n",
      "250/250 [==============================] - 124s 496ms/step - loss: 21.4111 - val_loss: 42.0965\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.9889\n",
      "Epoch 39: val_loss did not improve from 41.45439\n",
      "250/250 [==============================] - 119s 477ms/step - loss: 20.9889 - val_loss: 41.5959\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.6311\n",
      "Epoch 40: val_loss did not improve from 41.45439\n",
      "250/250 [==============================] - 119s 478ms/step - loss: 20.6311 - val_loss: 41.8589\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 21.1210\n",
      "Epoch 41: val_loss improved from 41.45439 to 41.23887, saving model to Models/Checkpoints\\mobilenetV2.hdf5\n",
      "250/250 [==============================] - 121s 483ms/step - loss: 21.1210 - val_loss: 41.2389\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.8889\n",
      "Epoch 42: val_loss did not improve from 41.23887\n",
      "250/250 [==============================] - 119s 477ms/step - loss: 20.8889 - val_loss: 41.3271\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.4153\n",
      "Epoch 43: val_loss did not improve from 41.23887\n",
      "250/250 [==============================] - 122s 486ms/step - loss: 20.4153 - val_loss: 41.3072\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.5496\n",
      "Epoch 44: val_loss did not improve from 41.23887\n",
      "250/250 [==============================] - 119s 477ms/step - loss: 20.5496 - val_loss: 41.5384\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.5488\n",
      "Epoch 45: val_loss did not improve from 41.23887\n",
      "250/250 [==============================] - 120s 480ms/step - loss: 20.5488 - val_loss: 42.1634\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.0944\n",
      "Epoch 46: val_loss did not improve from 41.23887\n",
      "250/250 [==============================] - 121s 486ms/step - loss: 20.0944 - val_loss: 41.4831\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 19.6384\n",
      "Epoch 47: val_loss did not improve from 41.23887\n",
      "250/250 [==============================] - 122s 488ms/step - loss: 19.6384 - val_loss: 41.9477\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 19.7676\n",
      "Epoch 48: val_loss did not improve from 41.23887\n",
      "250/250 [==============================] - 124s 496ms/step - loss: 19.7676 - val_loss: 41.8890\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 19.6672\n",
      "Epoch 49: val_loss did not improve from 41.23887\n",
      "250/250 [==============================] - 119s 475ms/step - loss: 19.6672 - val_loss: 41.4655\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - ETA: 0s - loss: 19.3944\n",
      "Epoch 50: val_loss did not improve from 41.23887\n",
      "250/250 [==============================] - 124s 497ms/step - loss: 19.3944 - val_loss: 41.5384\n"
     ]
    }
   ],
   "source": [
    "train_history = model.train(train_generator, val_generator, epochs=epochs, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07fa02e-5fca-471f-a5ce-68b5ff62a9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at Models/Trained/mobilenet_v2_custom.h5 \n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint that represents the weights with the lower validation loss during the training and save the model\n",
    "model.load_checkpoint()\n",
    "model.save_model(\"mobilenet_v2_custom.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c17820-0f3c-47f9-a908-0140f530336e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(train_history.history['loss'])\n",
    "plt.plot(train_history.history['val_loss'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.savefig('mobilenet_v2_custom.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5436162f-41b0-488c-bd3c-d6d4a5091477",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "\n",
    "ResNet needs a different batch size as the GPU runs out of memory otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1256acc-e251-4f37-8972-169b06dd2679",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_generator = DataGenerator(data_path=\"Data/train\", batch_size=batch_size, shuffle=True)\n",
    "val_generator = DataGenerator(data_path=\"Data/val\", batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c923dd77-c172-4d47-9d5e-ae113e5eceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "# Setup the learning rate decay (learning rate is 0.0001 for first 10 epochs, then becomes 0.00001 for next 20 epochs)\n",
    "lr_steps = [10*len(train_generator)]\n",
    "lr_values = [1e-4, 1e-5]\n",
    "lr_scheduler = tf.keras.optimizers.schedules.PiecewiseConstantDecay(lr_steps, lr_values)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a8a545-4dfd-4ab5-b0bc-76bcd26486c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.cast (TFOpLambda)        (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                36882     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,624,594\n",
      "Trainable params: 23,571,474\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = ResNetTuned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351a359-f88c-40b5-a9fa-1181a62d133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1798.4141\n",
      "Epoch 1: val_loss improved from inf to 811.87598, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 207s 196ms/step - loss: 1798.4141 - val_loss: 811.8760\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 247.9547\n",
      "Epoch 2: val_loss improved from 811.87598 to 218.33086, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 195s 195ms/step - loss: 247.9547 - val_loss: 218.3309\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 130.2859\n",
      "Epoch 3: val_loss did not improve from 218.33086\n",
      "1000/1000 [==============================] - 191s 191ms/step - loss: 130.2859 - val_loss: 287.8131\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 99.3253\n",
      "Epoch 4: val_loss improved from 218.33086 to 119.70675, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 195s 195ms/step - loss: 99.3253 - val_loss: 119.7067\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 76.4573\n",
      "Epoch 5: val_loss improved from 119.70675 to 83.83314, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 76.4573 - val_loss: 83.8331\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 66.8519\n",
      "Epoch 6: val_loss improved from 83.83314 to 79.47576, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 66.8519 - val_loss: 79.4758\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 41.8969\n",
      "Epoch 7: val_loss improved from 79.47576 to 68.24925, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 41.8969 - val_loss: 68.2493\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 32.6131\n",
      "Epoch 8: val_loss improved from 68.24925 to 57.73486, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 32.6131 - val_loss: 57.7349\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 62.6654\n",
      "Epoch 9: val_loss did not improve from 57.73486\n",
      "1000/1000 [==============================] - 192s 192ms/step - loss: 62.6654 - val_loss: 62.6007\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31.1737\n",
      "Epoch 10: val_loss did not improve from 57.73486\n",
      "1000/1000 [==============================] - 193s 193ms/step - loss: 31.1737 - val_loss: 59.4228\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 21.8737\n",
      "Epoch 11: val_loss improved from 57.73486 to 45.94373, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 195s 195ms/step - loss: 21.8737 - val_loss: 45.9437\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 19.2832\n",
      "Epoch 12: val_loss improved from 45.94373 to 43.59054, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 19.2832 - val_loss: 43.5905\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.9092\n",
      "Epoch 13: val_loss improved from 43.59054 to 43.08979, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 196s 195ms/step - loss: 17.9092 - val_loss: 43.0898\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 16.4735\n",
      "Epoch 14: val_loss improved from 43.08979 to 41.23064, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 16.4735 - val_loss: 41.2306\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 15.4589\n",
      "Epoch 15: val_loss improved from 41.23064 to 40.30097, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 195s 195ms/step - loss: 15.4589 - val_loss: 40.3010\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.7921\n",
      "Epoch 16: val_loss improved from 40.30097 to 38.90463, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 195s 195ms/step - loss: 14.7921 - val_loss: 38.9046\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.7290\n",
      "Epoch 17: val_loss did not improve from 38.90463\n",
      "1000/1000 [==============================] - 192s 192ms/step - loss: 13.7290 - val_loss: 39.5521\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.7896\n",
      "Epoch 18: val_loss improved from 38.90463 to 38.79506, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 195s 195ms/step - loss: 12.7896 - val_loss: 38.7951\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.2702\n",
      "Epoch 19: val_loss improved from 38.79506 to 38.08443, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 195s 195ms/step - loss: 12.2702 - val_loss: 38.0844\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.6013\n",
      "Epoch 20: val_loss did not improve from 38.08443\n",
      "1000/1000 [==============================] - 192s 191ms/step - loss: 11.6013 - val_loss: 38.2598\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.0055\n",
      "Epoch 21: val_loss improved from 38.08443 to 37.20993, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 195s 195ms/step - loss: 11.0055 - val_loss: 37.2099\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.2654\n",
      "Epoch 22: val_loss did not improve from 37.20993\n",
      "1000/1000 [==============================] - 192s 192ms/step - loss: 10.2654 - val_loss: 37.6826\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.8093\n",
      "Epoch 23: val_loss improved from 37.20993 to 37.02734, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 9.8093 - val_loss: 37.0273\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.5848\n",
      "Epoch 24: val_loss improved from 37.02734 to 36.88442, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 198s 198ms/step - loss: 9.5848 - val_loss: 36.8844\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.0771\n",
      "Epoch 25: val_loss improved from 36.88442 to 35.95645, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 9.0771 - val_loss: 35.9565\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.4692\n",
      "Epoch 26: val_loss improved from 35.95645 to 35.93785, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 8.4692 - val_loss: 35.9379\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.1177\n",
      "Epoch 27: val_loss did not improve from 35.93785\n",
      "1000/1000 [==============================] - 193s 193ms/step - loss: 8.1177 - val_loss: 36.0179\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.9940\n",
      "Epoch 28: val_loss improved from 35.93785 to 35.45473, saving model to Models/Checkpoints\\resnet50.hdf5\n",
      "1000/1000 [==============================] - 197s 197ms/step - loss: 7.9940 - val_loss: 35.4547\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.6329\n",
      "Epoch 29: val_loss did not improve from 35.45473\n",
      "1000/1000 [==============================] - 194s 193ms/step - loss: 7.6329 - val_loss: 36.3387\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.3760"
     ]
    }
   ],
   "source": [
    "train_history = model.train(train_generator, val_generator, epochs=epochs, optimizer=optimizer, loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dc7dd2-3954-4be9-951e-b242c5876ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint that represents the weights with the lower validation loss during the training and save the model\n",
    "model.load_checkpoint()\n",
    "model.save_model(\"resnet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da1a798-96c1-4289-abb2-65c13b7b637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(train_history.history['loss'])\n",
    "plt.plot(train_history.history['val_loss'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.savefig('resnet.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "dl_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
